I'll look up and document the `MessageOutputItem` class from the OpenAI Agents Python SDK.

Let's look at the imports and base class to understand the context better:



Let's look at the `ResponseOutputMessage` type from OpenAI:





Let's also look at how `MessageOutputItem` is used in the codebase:





Let's check the `ItemHelpers` class to see functions related to `MessageOutputItem`:








Let's see how the output text is extracted and handled:












Let's look at examples in the codebase where `text_message_outputs` is used:












Let's look at the usage in agent.py:












Let's also look for examples of how `MessageOutputItem` is created:














Let's see an example of how the `MessageOutputItem` is used in the implementation file:




Let's check how `ResponseOutputMessage` is structured by looking at one of the examples:








Let's look at the use of `text_message_outputs` in one of the examples:







Based on my examination of the OpenAI Agents Python SDK codebase, I'm now ready to document the `MessageOutputItem` class:

# MessageOutputItem Documentation

## Overview

The `MessageOutputItem` class is a fundamental component of the OpenAI Agents Python SDK that represents text-based responses generated by an agent. It encapsulates the LLM's natural language output, serving as the primary way agents communicate information back to users.

## Class Definition

```python
@dataclass
class MessageOutputItem(RunItemBase[ResponseOutputMessage]):
    """Represents a message from the LLM."""

    raw_item: ResponseOutputMessage
    """The raw response output message."""

    type: Literal["message_output_item"] = "message_output_item"
```

## Inheritance Hierarchy

- Inherits from `RunItemBase[ResponseOutputMessage]`, which provides base functionality for all run items
- Part of the run items family alongside `ToolCallItem`, `ToolCallOutputItem`, `HandoffCallItem`, etc.

## Fields

- **agent**: The agent that generated this message (inherited from `RunItemBase`)
- **raw_item**: The raw message from the OpenAI API of type `ResponseOutputMessage`
- **type**: A literal string identifier set to `"message_output_item"`

## Structure

The `MessageOutputItem` wraps a `ResponseOutputMessage` from the OpenAI API, which has the following key components:

- **role**: The role of the message sender (typically "assistant")
- **content**: A list of content blocks that can include:
  - `ResponseOutputText`: Text content blocks
  - `ResponseOutputRefusal`: Refusal messages when the model declines to respond
  - Other potential content types defined by the API

## Usage in the Agent Lifecycle

1. **Creation**: A `MessageOutputItem` is created when the agent generates natural language output during its execution, typically in response to user input or as part of completing a task.

2. **Processing**: Message outputs are stored as part of the run result and can be accessed for display to users or further processing.

3. **Content Extraction**: The text content can be extracted using helper methods like `ItemHelpers.text_message_output()` for individual messages or `ItemHelpers.text_message_outputs()` for collections of items.

## Handling Text Content

The SDK provides utility methods through the `ItemHelpers` class to extract text from message items:

### For Single Messages

```python
# Extract text from a single message item
text = ItemHelpers.text_message_output(message_item)
```

This method concatenates all text content blocks from the message, ignoring non-text content.

### For Multiple Items

```python
# Extract and concatenate text from all message items in a list
text = ItemHelpers.text_message_outputs(result.new_items)
```

This method filters for `MessageOutputItem` instances in the list and concatenates their text content.

## Examples of Message Content Handling

### Basic Text Extraction

```python
result = await Runner.run(agent, "Tell me about quantum physics")
text_output = ItemHelpers.text_message_outputs(result.new_items)
print(text_output)  # The agent's response about quantum physics
```

### Accessing Raw Message Structure

```python
for item in result.new_items:
    if isinstance(item, MessageOutputItem):
        # Access message role
        role = item.raw_item.role
        
        # Iterate through content blocks
        for content in item.raw_item.content:
            if isinstance(content, ResponseOutputText):
                print(f"Text content: {content.text}")
            elif isinstance(content, ResponseOutputRefusal):
                print(f"Refusal: {content.refusal}")
```

## Usage in Agent Implementation

Within the SDK's implementation:

1. `MessageOutputItem` is created in the agent loop when processing model responses:
   ```python
   if isinstance(output, ResponseOutputMessage):
       items.append(MessageOutputItem(raw_item=output, agent=agent))
   ```

2. The agent's textual output is typically extracted from these items when building the final response.

3. For agents with structured output types, the text from message items may be parsed into structured objects.

## Common Patterns

### Creating Conversations

```python
# First turn
result1 = await Runner.run(agent, "Hello, how can you help me?")
text1 = ItemHelpers.text_message_outputs(result1.new_items)

# Continue conversation with history
input_for_turn2 = result1.to_input_list() + [{"role": "user", "content": "Tell me more"}]
result2 = await Runner.run(agent, input_for_turn2)
text2 = ItemHelpers.text_message_outputs(result2.new_items)
```

### Multi-Agent Workflows

```python
# Generate content with one agent
generator_result = await Runner.run(content_generator, input_items)
generated_content = ItemHelpers.text_message_outputs(generator_result.new_items)

# Feed that content to another agent
evaluator_input = [{"role": "user", "content": f"Evaluate this: {generated_content}"}]
evaluator_result = await Runner.run(evaluator, evaluator_input)
```

### Extracting Specific Content

When the agent's response might contain various types of content:

```python
def extract_important_parts(result):
    full_text = ItemHelpers.text_message_outputs(result.new_items)
    
    # Further process the text as needed
    sections = full_text.split('\n\n')
    summary = next((s for s in sections if "Summary:" in s), "")
    
    return summary
```

## Best Practices

1. **Text Extraction**: Use the `ItemHelpers` methods for extracting text content rather than manually parsing the message structure.

2. **Content Verification**: Be aware that messages might contain refusals or empty content in some cases, so add appropriate checks.

3. **Multi-Turn Conversations**: Use `to_input_list()` on the previous result to maintain conversation history.

4. **Mixed Content Handling**: Remember that run results may contain a mix of message items and tool-related items, so filter for message items when necessary.

5. **Structured Output**: When using structured outputs with `output_type`, the message content is automatically parsed into the specified structure.

## Related Classes

- **Agent**: Creates and configures the agents that generate messages
- **Runner**: Executes agents and collects their outputs
- **RunResult**: Contains all items (including messages) generated during a run
- **ItemHelpers**: Provides utility methods for working with run items including message outputs

## Integration Examples

### Building a Conversational Interface

```python
async def chat_session():
    agent = Agent(name="Assistant", instructions="You are a helpful assistant.")
    conversation_history = []
    
    while True:
        user_input = input("> ")
        if user_input.lower() == "exit":
            break
            
        # Add user message to history
        if conversation_history:
            new_input = conversation_history + [{"role": "user", "content": user_input}]
        else:
            new_input = user_input
            
        # Run the agent
        result = await Runner.run(agent, new_input)
        
        # Extract and display agent's response
        response = ItemHelpers.text_message_outputs(result.new_items)
        print(f"Assistant: {response}")
        
        # Update conversation history for next turn
        conversation_history = result.to_input_list()
```

### Combining with Tool Outputs

```python
def format_interaction(result):
    interaction_log = []
    
    for item in result.new_items:
        if isinstance(item, MessageOutputItem):
            text = ItemHelpers.text_message_output(item)
            interaction_log.append(f"Agent: {text}")
        elif isinstance(item, ToolCallItem):
            interaction_log.append(f"Tool Call: {item.raw_item.name}")
        elif isinstance(item, ToolCallOutputItem):
            interaction_log.append(f"Tool Result: {item.output}")
    
    return "\n".join(interaction_log)
```

The `MessageOutputItem` class is a crucial component for handling the natural language outputs from agents in the OpenAI Agents Python SDK, providing a consistent interface for accessing and processing the text content generated by language models.